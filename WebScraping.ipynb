{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean(string):\n",
    "    retval = re.sub(r'<.+?>', '', string)\n",
    "    rmv = \"Have an opinion on this story? Share it!\"\n",
    "    retval = retval.split(rmv, 1)[0]\n",
    "    retval = re.sub(r'\\b.+\\xa0', '', retval).replace('\\n, ', '').lower()\n",
    "    retval = re.sub(r'\\n\\n\\n\\n\\n.+', '', retval).replace('\\n', '')\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoupScraping(URL):\n",
    "    column_names = ['articleid', 'url', 'title', 'content', 'sources']\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    article_id = 1\n",
    "    \n",
    "    condition = True\n",
    "    while condition:\n",
    "        source = requests.get(URL).content\n",
    "        soup = bs.BeautifulSoup(source, 'lxml')\n",
    "        \n",
    "        url_list = []\n",
    "        headers = []\n",
    "        for urls in soup.find_all('div', id='mw-pages'):\n",
    "            url_list.extend(urls.find_all('a'))\n",
    "            headers.extend(urls.find_all(re.compile(r'^h[1-6]$')))\n",
    "        \n",
    "        if headers[-1].text >= 'F' and headers[-1].text <= 'O':\n",
    "            print(\"Scraping articles from:\", URL)\n",
    "        else: \n",
    "            condition = False\n",
    "            \n",
    "        URL = 'https://en.wikinews.org' + url_list[1]['href']\n",
    "        for url in url_list[2:-2]:\n",
    "            article_url = \"https://en.wikinews.org\" + url['href']\n",
    "            \n",
    "            # Just in case server is overloaded\n",
    "            try:\n",
    "                article_source = requests.get(article_url, timeout=2.5)\n",
    "            except:\n",
    "                print(\"Connection timed out - Retrying request...\")\n",
    "                article_source = requests.get(article_url, timeout=2.5)\n",
    "                \n",
    "            content = article_source.content\n",
    "            article_soup = bs.BeautifulSoup(content, 'lxml')\n",
    "            \n",
    "            article_title = article_soup.find(class_='firstHeading').text\n",
    "            \n",
    "            text_list = []\n",
    "            for text in article_soup.find_all(class_='mw-parser-output'):\n",
    "                text_list.extend(text.find_all('p'))\n",
    "            \n",
    "            text = clean(str(text_list))\n",
    "            \n",
    "            sources_list = []\n",
    "            for source in article_soup.find_all('a', rel='nofollow', class_='external text'):\n",
    "                sources_list.append(source['href'])\n",
    "            \n",
    "            df = df.append({'articleid':article_id, 'url':article_url, 'title':article_title\n",
    "                            , 'content':text, 'sources':sources_list},\n",
    "                            ignore_index=True)\n",
    "            article_id += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group_nr = 5\n",
    "urls = []\n",
    "for char in \"ABCDEFGHIJKLMNOPRSTUVWZABCDEFGHIJKLMNOPRSTUVWZ\"[group_nr%23:group_nr%23+10]:\n",
    "    urls.append('https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&from=' + char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&from=F\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Former+Managing+Director+of+Gambian+newspaper+appears+in+court&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Gaddafi+loyalists+allegedly+using+Red+Cross+helicopters+to+bomb+rebel+held+city&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Gujarat+high+court+refutes+Modi%27s+objection+to+Lokyukta%27s+appointment&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Illinois+Governor+Blagojevich+appoints+Roland+Burris+for+vacated+U.S.+Senate+seat&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Iran+resumes+nuclear+research&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Israel+pushes+further+into+Lebanon&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Jordanian+king+dissolves+parliament%2C+calls+for+general+election+two+years+ahead+of+schedule&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Lebanon+faces+humanitarian+crisis&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Mauritania+cuts+ties+with+Israel%2C+expels+Israeli+diplomats&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Musharraf+denies+making+rape+remarks&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=New+Zealand+Parliament+reconvenes+after+election&subcatfrom=F&filefrom=F#mw-pages\n",
      "Scraping articles from: https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&pagefrom=Obama+announces+plan+to+build+roads%2C+railroads+and+runways&subcatfrom=F&filefrom=F#mw-pages\n"
     ]
    }
   ],
   "source": [
    "def retSoup():\n",
    "    return SoupScraping('https://en.wikinews.org/w/index.php?title=Category:Politics_and_conflicts&from=F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleid</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://en.wikinews.org/wiki/Face_coverings_to...</td>\n",
       "      <td>Face coverings to be mandatory on public trans...</td>\n",
       "      <td>[, yesterday, england's transport secretary, g...</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-52927089, https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://en.wikinews.org/wiki/Face-off_at_Islam...</td>\n",
       "      <td>Face-off at Islamabad Mosque</td>\n",
       "      <td>[since last tuesday, following violent confron...</td>\n",
       "      <td>[http://news.bbc.co.uk/1/hi/world/south_asia/6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://en.wikinews.org/wiki/Facebook_blocked_...</td>\n",
       "      <td>Facebook blocked in Bangladesh</td>\n",
       "      <td>[bangladesh temporarily blocked the social net...</td>\n",
       "      <td>[http://www.thedailystar.net/newDesign/news-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://en.wikinews.org/wiki/Facebook_takes_do...</td>\n",
       "      <td>Facebook takes down groups supporting Austin c...</td>\n",
       "      <td>[on the popular social networking website face...</td>\n",
       "      <td>[http://www.azcentral.com/news/articles/2010/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://en.wikinews.org/wiki/Failings_identifi...</td>\n",
       "      <td>Failings identified in response to Iranian sei...</td>\n",
       "      <td>[two inquiries into the seizure of royal navy ...</td>\n",
       "      <td>[http://news.bbc.co.uk/1/hi/uk_politics/676590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2796</td>\n",
       "      <td>https://en.wikinews.org/wiki/Photo_essay:_Vale...</td>\n",
       "      <td>Photo essay: Valentine's Day at the U.S. Viet ...</td>\n",
       "      <td>[washington, d.c. —the vietnam veterans memori...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2797</td>\n",
       "      <td>https://en.wikinews.org/wiki/Pickens_County,_S...</td>\n",
       "      <td>Pickens County, South Carolina sheriff refuses...</td>\n",
       "      <td>[on friday, the sheriff of pickens county, sou...</td>\n",
       "      <td>[http://www.foxnews.com/politics/2013/12/08/sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2798</td>\n",
       "      <td>https://en.wikinews.org/wiki/Pilot_with_9/11_l...</td>\n",
       "      <td>Pilot with 9/11 links deported from New Zealand</td>\n",
       "      <td>[a yemeni man linked to the september 11, 2001...</td>\n",
       "      <td>[https://www.beehive.govt.nz/ViewDocument.aspx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>2799</td>\n",
       "      <td>https://en.wikinews.org/wiki/Pirate_attacks_br...</td>\n",
       "      <td>Pirate attacks bring UN aid to Somalia to a halt</td>\n",
       "      <td>[on saturday, may 19, a ship chartered by the ...</td>\n",
       "      <td>[http://www.voanews.com/english/Africa/2007-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>2800</td>\n",
       "      <td>https://en.wikinews.org/wiki/Plane_carrying_ar...</td>\n",
       "      <td>Plane carrying arms to Nepal detained in Gujarat</td>\n",
       "      <td>[a russian-made aircraft carrying sophisticate...</td>\n",
       "      <td>[http://www.ibnlive.com/news/arms-plane-to-nep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     articleid                                                url  \\\n",
       "0            1  https://en.wikinews.org/wiki/Face_coverings_to...   \n",
       "1            2  https://en.wikinews.org/wiki/Face-off_at_Islam...   \n",
       "2            3  https://en.wikinews.org/wiki/Facebook_blocked_...   \n",
       "3            4  https://en.wikinews.org/wiki/Facebook_takes_do...   \n",
       "4            5  https://en.wikinews.org/wiki/Failings_identifi...   \n",
       "...        ...                                                ...   \n",
       "2795      2796  https://en.wikinews.org/wiki/Photo_essay:_Vale...   \n",
       "2796      2797  https://en.wikinews.org/wiki/Pickens_County,_S...   \n",
       "2797      2798  https://en.wikinews.org/wiki/Pilot_with_9/11_l...   \n",
       "2798      2799  https://en.wikinews.org/wiki/Pirate_attacks_br...   \n",
       "2799      2800  https://en.wikinews.org/wiki/Plane_carrying_ar...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Face coverings to be mandatory on public trans...   \n",
       "1                          Face-off at Islamabad Mosque   \n",
       "2                        Facebook blocked in Bangladesh   \n",
       "3     Facebook takes down groups supporting Austin c...   \n",
       "4     Failings identified in response to Iranian sei...   \n",
       "...                                                 ...   \n",
       "2795  Photo essay: Valentine's Day at the U.S. Viet ...   \n",
       "2796  Pickens County, South Carolina sheriff refuses...   \n",
       "2797    Pilot with 9/11 links deported from New Zealand   \n",
       "2798   Pirate attacks bring UN aid to Somalia to a halt   \n",
       "2799   Plane carrying arms to Nepal detained in Gujarat   \n",
       "\n",
       "                                                content  \\\n",
       "0     [, yesterday, england's transport secretary, g...   \n",
       "1     [since last tuesday, following violent confron...   \n",
       "2     [bangladesh temporarily blocked the social net...   \n",
       "3     [on the popular social networking website face...   \n",
       "4     [two inquiries into the seizure of royal navy ...   \n",
       "...                                                 ...   \n",
       "2795  [washington, d.c. —the vietnam veterans memori...   \n",
       "2796  [on friday, the sheriff of pickens county, sou...   \n",
       "2797  [a yemeni man linked to the september 11, 2001...   \n",
       "2798  [on saturday, may 19, a ship chartered by the ...   \n",
       "2799  [a russian-made aircraft carrying sophisticate...   \n",
       "\n",
       "                                                sources  \n",
       "0     [https://www.bbc.co.uk/news/uk-52927089, https...  \n",
       "1     [http://news.bbc.co.uk/1/hi/world/south_asia/6...  \n",
       "2     [http://www.thedailystar.net/newDesign/news-de...  \n",
       "3     [http://www.azcentral.com/news/articles/2010/0...  \n",
       "4     [http://news.bbc.co.uk/1/hi/uk_politics/676590...  \n",
       "...                                                 ...  \n",
       "2795                                                 []  \n",
       "2796  [http://www.foxnews.com/politics/2013/12/08/sc...  \n",
       "2797  [https://www.beehive.govt.nz/ViewDocument.aspx...  \n",
       "2798  [http://www.voanews.com/english/Africa/2007-05...  \n",
       "2799  [http://www.ibnlive.com/news/arms-plane-to-nep...  \n",
       "\n",
       "[2800 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formats = [\"%B %d %Y\", \"%d %B %Y\", \"%b %d %Y\", \"%m/%d/%Y\", \"%m %d %Y\"]\n",
    "published = df['published']\n",
    "\n",
    "all_dates = []\n",
    "for publish in published:\n",
    "    if publish != 'None':\n",
    "        date = re.sub(r'^.*?, ', '', publish).replace(',','')\n",
    "\n",
    "        for format in formats:\n",
    "            try:\n",
    "                all_dates.append(datetime.strptime(date, format).strftime(\"%Y-%m-%d\"))\n",
    "            except ValueError:\n",
    "            pass\n",
    "sorted_dates = sorted(all_dates)\n",
    "pd_sorted_dates = pd.DataFrame(sorted_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCREATE TABLE IF NOT EXISTS Webarticle (\\n      articleID INT NOT NULL PRIMARY KEY,\\n      url VARCHAR NOT NULL UNIQUE,\\n      title VARCHAR NULL,\\n      webcontent VARCHAR NULL,\\n      sources VARCHAR NULL\\n    );\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE TABLE FOR SCRAPED ARTICLES\n",
    "'''\n",
    "CREATE TABLE IF NOT EXISTS Webarticle (\n",
    "      articleID INT NOT NULL PRIMARY KEY,\n",
    "      url VARCHAR NOT NULL UNIQUE,\n",
    "      title VARCHAR NULL,\n",
    "      webcontent VARCHAR NULL,\n",
    "      sources VARCHAR NULL\n",
    "    );\n",
    "'''\n",
    "# CREATE VIEW \n",
    "'''\n",
    "CREATE VIEW [article vs webarticle] AS SELECT \n",
    "    a.articleID, a.title, a.content, a.inserted_at, \n",
    "    w.webarticleID, w.webtitle, w.webcontent, w.published\n",
    "    FROM article a, webarticle w;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import psycopg2, time, re\n",
    "\n",
    "# Make connection to database\n",
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"2ybftbchx7bfgkv\",\n",
    "    host = \"localhost\",\n",
    "    port = \"5432\",\n",
    "    database = \"DataScience\")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "def insertTable(cols, vals, target):\n",
    "        try: \n",
    "            sql = \"INSERT INTO \"+target+\" (\" +cols + \") VALUES (\" + \"%s,\"*(len(vals.iloc[0])-1) + \"%s)\"\n",
    "            cursor.executemany(sql, vals.values.tolist())\n",
    "            connection.commit()\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong with: %s %s\" % (target, str(e)))\n",
    "\n",
    "\n",
    "article = df.iloc[:,[0,1,2,3,4]]\n",
    "articleval = \"articleID, url, title, webcontent, sources\"\n",
    "insertTable(articleval, article, \"webarticle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
